{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondae8929445447b42c891dc62f0523a76ee",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "数据处理工具 torch.utils 和 torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.Data = np.asarray([\n",
    "            [1, 2],\n",
    "            [3, 4],\n",
    "            [2, 1],\n",
    "            [3, 4],\n",
    "            [4, 5],\n",
    "        ])  # 数据集\n",
    "        self.Label = np.asarray([0, 1, 0, 1, 2])  # 对应的标签\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        txt = torch.from_numpy(self.Data[index])\n",
    "        label = torch.tensor(self.Label[index])\n",
    "        return txt, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TestDataset()\n",
    "print(t[2])\n",
    "print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows 下 num_workers 参数如果设置大于 0 会调用 multiprocessing 模块, 需要在 __name__ == '__main__' 下运行\n",
    "# https://pytorch.org/docs/stable/data.html#platform-specific-behaviors\n",
    "loader = DataLoader(t, batch_size=2, shuffle=False, num_workers=0)\n",
    "for i, train_data in enumerate(loader):\n",
    "    print('i:', i)\n",
    "    print('data:', train_data[0])\n",
    "    print('label:', train_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(loader)\n",
    "print(next(dataiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Net(\n  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc1): Linear(in_features=320, out_features=50, bias=True)\n  (fc2): Linear(in_features=50, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.bn = nn.BatchNorm2d(20)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2_drop(self.conv2(x))))\n",
    "        x = self.bn(x)\n",
    "        x = x.view(-1, 20 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "print(Net())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化网络\n",
    "input = torch.rand(32, 1, 28, 28)\n",
    "model = Net()\n",
    "with SummaryWriter(log_dir='logs', comment='Net') as w:\n",
    "    w.add_graph(model, (input, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "使用以下命令启动 tensorboard\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=logs --port=6006\n",
    "tensorboard --logdir='D:\\code\\pytorch_learn\\logs' --port=6006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化损失值\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epoches = 60\n",
    "learning_rate = 0.01\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "writer = SummaryWriter(log_dir='logs',comment='Linear')\n",
    "np.random.seed(100) \n",
    "x_train = np.linspace(-1, 1, 100).reshape(100,1) \n",
    "y_train = 3*np.power(x_train, 2) +2+ 0.2*np.random.rand(x_train.size).reshape(100,1) \n",
    "\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    inputs = torch.from_numpy(x_train).type(dtype)\n",
    "    targets = torch.from_numpy(y_train).type(dtype)\n",
    "\n",
    "    output = model(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 保存loss的数据与epoch数值\n",
    "    writer.add_scalar('训练损失值', loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化特征图\n",
    "import torchvision.utils as utils\n",
    "# writer = SummaryWriter(log_dir='logs', comment='feature map')\n",
    "# img_grid = utils.make_grid(x, normalize=True, scale_each=True, nrow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "# 数据集\n",
    "from torchvision.datasets import mnist\n",
    "# 预处理模块\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# nn 及 优化器\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "cuda:0\nNet(\n  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc1): Linear(in_features=320, out_features=50, bias=True)\n  (fc2): Linear(in_features=50, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 128\n",
    "num_epoches = 5\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "# 下载数据\n",
    "train_dataset = mnist.MNIST('./data', train=True, transform=transform, download=True)\n",
    "test_dataset = mnist.MNIST('./data', train=False, transform=transform, download=True)\n",
    "# dataloader 是个可迭代对象\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "# 模型和优化器\n",
    "model = Net()\n",
    "model.to(device)  # 注意, 模型也要迁移到 device 上\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "train_dataset length: 60000\ntrain_loader length: 938\n[0] loss: 1.522, acc: 0.939\n[1] loss: 1.525, acc: 0.936\n"
    }
   ],
   "source": [
    "# 训练模型\n",
    "print('train_dataset length:', len(train_dataset))\n",
    "print('train_loader length:', len(train_loader))\n",
    "len_train_loader = len(train_loader)\n",
    "\n",
    "for epoch in range(2):  \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # 获取训练数据\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 权重参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向及反向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累加损失值\n",
    "        running_loss += loss.item()\n",
    "        # 计算分类的准确率\n",
    "        _, pred = outputs.max(1)\n",
    "        num_correct = (pred == labels).sum().item()\n",
    "        running_acc += num_correct / inputs.shape[0]\n",
    "    \n",
    "    # 显示损失值\n",
    "    print('[{}] loss: {:.3f}, acc: {:.3f}'.format(\n",
    "        epoch,\n",
    "        running_loss / len_train_loader,\n",
    "        running_acc / len_train_loader,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(28 * 28, 300, 100, 10)\n",
    "PATH = './model/mnist_model.pth'\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "torch.Size([1, 1, 28, 28])\n"
    }
   ],
   "source": [
    "model.eval()\n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "x = inputs[0].unsqueeze(0)  # 取出一条数据\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[0.1028, 0.0885, 0.1019, 0.1087, 0.0963, 0.0930, 0.1020, 0.1137, 0.0882,\n         0.1049]], device='cuda:0', grad_fn=<SoftmaxBackward>)\ntorch.Size([1, 10])\ntorch.Size([1, 1, 28, 28])\ntorch.Size([1, 1, 28, 28])\nconv1\ntorch.Size([1, 10, 24, 24])\ntorch.Size([1, 10, 24, 24])\npool1\ntorch.Size([1, 10, 12, 12])\ntorch.Size([1, 10, 12, 12])\nconv2\ntorch.Size([1, 20, 8, 8])\ntorch.Size([1, 20, 8, 8])\nconv2_drop\ntorch.Size([1, 20, 8, 8])\ntorch.Size([1, 20, 8, 8])\npool2\ntorch.Size([1, 20, 4, 4])\ntorch.Size([1, 20, 4, 4])\nbn\ntorch.Size([1, 20, 4, 4])\ntorch.Size([1, 320])\nfc1\ntorch.Size([1, 50])\ntorch.Size([1, 50])\nfc2\n"
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir='logs', comment='feature map')\n",
    "out = model(x)\n",
    "print(out)\n",
    "print(out.shape)\n",
    "for name, layer in model._modules.items():\n",
    "    # 为fc层预处理x\n",
    "    print(x.shape)\n",
    "    x = x.view(x.size(0), -1) if \"fc\" in name else x\n",
    "    print(x.size())\n",
    "    print(f'{name}')\n",
    "\n",
    "    x = layer(x)\n",
    "\n",
    "    # 查看卷积层的特征图\n",
    "    if  'layer' in name or 'conv' in name:\n",
    "        x1 = x.transpose(0, 1)  # C，B, H, W  ---> B，C, H, W\n",
    "        img_grid = utils.make_grid(x1, normalize=True, scale_each=True, nrow=4)  # normalize进行归一化处理\n",
    "        writer.add_image(f'{name}_feature_maps', img_grid, global_step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}